{"ast":null,"code":"var _jsxFileName = \"/home/sv/LazyHacks/study-tracker-ui/src/pages/LearningAssist.js\",\n  _s = $RefreshSig$();\n// LearningAssist.js\n\nimport React, { useState } from 'react';\nimport { useNavigate } from 'react-router-dom';\nimport './LearningAssist.css';\nimport Header from '../components/Header';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nfunction LearningAssist() {\n  _s();\n  const [currentTab, setCurrentTab] = useState('Research Assistant');\n  const [arxivLink, setArxivLink] = useState('');\n  const [selectedFile, setSelectedFile] = useState(null);\n  const [pdfFile, setPdfFile] = useState(null);\n  const [videoFile, setVideoFile] = useState(null); // Added state for video file\n  const [notes, setNotes] = useState(null);\n  const navigate = useNavigate();\n  const handleLinkSubmission = () => {\n    setSelectedFile(arxivLink);\n    setArxivLink('');\n  };\n  const handleFileUpload = event => {\n    setPdfFile(event.target.files[0]);\n  };\n  const handleVideoUpload = event => {\n    setVideoFile(event.target.files[0]);\n  };\n  const navigateToSmartAssistant = () => {\n    if (pdfFile) {\n      navigate('/smart-assistant', {\n        state: {\n          uploadedFile: pdfFile.name\n        }\n      });\n    } else if (selectedFile) {\n      navigate('/smart-assistant', {\n        state: {\n          uploadedFile: selectedFile\n        }\n      });\n    }\n  };\n  const handleGenerateNotes = () => {\n    setNotes(\"These are the generated notes from the video...\"); // Placeholder text\n    setSummary(`MLP-Mixer: An All-MLP Architecture for Vision<br><br>\n      <strong>Authors:</strong> Ilya Tolstikhin, Neil Houlsby, Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, et al.<br>\n      <strong>Source:</strong> Google Research, Brain Team<br><br>\n      ---\n      <h3>Background</h3>\n      Traditional computer vision models rely on either Convolutional Neural Networks (CNNs), which apply convolution operations to extract spatial features, or Vision Transformers (ViTs), which use self-attention to capture global dependencies. However, the authors challenge this paradigm by proposing that neither convolutions nor attention mechanisms are strictly necessary to achieve high performance in image classification.<br><br>\n      ---\n      <h3>Introduction to MLP-Mixer</h3>\n      The MLP-Mixer is a new approach that relies solely on Multi-Layer Perceptrons (MLPs) without any convolution or self-attention layers. The architecture consists of two primary layers: token-mixing MLPs and channel-mixing MLPs. Token-mixing MLPs combine information across different spatial locations, while channel-mixing MLPs mix features across channels at each spatial location. Together, these layers allow the model to learn both spatial and channel relationships in the data.<br><br>\n      ---\n      <h3>Architecture Design</h3>\n      The MLP-Mixer architecture processes images in non-overlapping patches, similarly to Vision Transformers. The patches are first projected linearly to create a matrix with dimensions corresponding to the number of patches and channels. Each MLP-Mixer layer contains:\n      <ul>\n        <li><strong>Token-mixing MLP:</strong> Processes spatial data across patches, facilitating the integration of spatial information.</li>\n        <li><strong>Channel-mixing MLP:</strong> Mixes channel data independently for each patch, capturing feature interactions across channels.</li>\n      </ul>\n      These layers are interleaved to enable a complete spatial and channel interaction across the image.<br><br>\n      ---\n      <h3>Experiments and Results</h3>\n      MLP-Mixer was pre-trained on large datasets (e.g., ImageNet, JFT-300M) and evaluated on various image classification benchmarks. When compared to CNNs and Transformers, MLP-Mixer achieved competitive results, especially on large datasets, with minimal complexity. It achieved up to 87.94% top-1 accuracy on ImageNet, demonstrating that even without convolutions or attention, it could perform on par with state-of-the-art models.<br><br>\n      ---\n      <h3>Conclusion</h3>\n      The MLP-Mixer presents a simple yet effective alternative for vision tasks, challenging the need for complex convolution or attention layers in achieving high accuracy. Its design opens up new possibilities for vision architectures by demonstrating that MLP-based structures can capture the necessary dependencies in image data. The authors hope this work inspires further research into MLP-based architectures across various domains.\n      `);\n  };\n  const renderContent = () => {\n    if (currentTab === 'Research Assistant') {\n      return /*#__PURE__*/_jsxDEV(\"div\", {\n        className: \"link-input\",\n        children: [/*#__PURE__*/_jsxDEV(\"input\", {\n          type: \"text\",\n          placeholder: \"Enter arXiv link\",\n          value: arxivLink,\n          onChange: e => setArxivLink(e.target.value)\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 70,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n          onClick: handleLinkSubmission,\n          children: \"View Paper\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 76,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n          className: \"smart-assistant-button\",\n          onClick: navigateToSmartAssistant,\n          disabled: !selectedFile,\n          children: \"Smart Assistant\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 77,\n          columnNumber: 11\n        }, this), selectedFile && /*#__PURE__*/_jsxDEV(\"iframe\", {\n          src: selectedFile,\n          title: \"Research Paper\",\n          style: {\n            width: '100%',\n            height: '90vh',\n            border: 'none'\n          }\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 85,\n          columnNumber: 13\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 69,\n        columnNumber: 9\n      }, this);\n    } else if (currentTab === 'Personal Tutor') {\n      return /*#__PURE__*/_jsxDEV(\"div\", {\n        className: \"tutor-section\",\n        children: [/*#__PURE__*/_jsxDEV(\"input\", {\n          type: \"file\",\n          onChange: handleFileUpload\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 96,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n          onClick: navigateToSmartAssistant,\n          disabled: !pdfFile,\n          children: \"Smart Assistant\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 97,\n          columnNumber: 11\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 95,\n        columnNumber: 9\n      }, this);\n    } else if (currentTab === 'Video to Note Maker') {\n      return /*#__PURE__*/_jsxDEV(\"div\", {\n        className: \"video-note-section\",\n        children: [/*#__PURE__*/_jsxDEV(\"p\", {\n          children: \"Upload a video to generate notes.\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 108,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"input\", {\n          type: \"file\",\n          accept: \"video/*\",\n          onChange: handleVideoUpload\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 109,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n          onClick: handleGenerateNotes,\n          disabled: !videoFile,\n          children: \"Generate Notes\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 110,\n          columnNumber: 11\n        }, this), notes && /*#__PURE__*/_jsxDEV(\"div\", {\n          className: \"notes-box\",\n          children: /*#__PURE__*/_jsxDEV(\"p\", {\n            children: notes\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 113,\n            columnNumber: 15\n          }, this)\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 112,\n          columnNumber: 13\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 107,\n        columnNumber: 9\n      }, this);\n    }\n  };\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"learning-assist-page\",\n    children: [/*#__PURE__*/_jsxDEV(Header, {}, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 123,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"tab-buttons\",\n      children: [/*#__PURE__*/_jsxDEV(\"button\", {\n        onClick: () => setCurrentTab('Personal Tutor'),\n        children: \"Personal Tutor\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 125,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n        onClick: () => setCurrentTab('Research Assistant'),\n        children: \"Research Assistant\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 126,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n        onClick: () => setCurrentTab('Video to Note Maker'),\n        children: \"Video to Note Maker\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 127,\n        columnNumber: 9\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 124,\n      columnNumber: 7\n    }, this), renderContent()]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 122,\n    columnNumber: 5\n  }, this);\n}\n_s(LearningAssist, \"bJCsUwPhZPDbTvffnhy3wdV0rjs=\", false, function () {\n  return [useNavigate];\n});\n_c = LearningAssist;\nexport default LearningAssist;\nvar _c;\n$RefreshReg$(_c, \"LearningAssist\");","map":{"version":3,"names":["React","useState","useNavigate","Header","jsxDEV","_jsxDEV","LearningAssist","_s","currentTab","setCurrentTab","arxivLink","setArxivLink","selectedFile","setSelectedFile","pdfFile","setPdfFile","videoFile","setVideoFile","notes","setNotes","navigate","handleLinkSubmission","handleFileUpload","event","target","files","handleVideoUpload","navigateToSmartAssistant","state","uploadedFile","name","handleGenerateNotes","setSummary","renderContent","className","children","type","placeholder","value","onChange","e","fileName","_jsxFileName","lineNumber","columnNumber","onClick","disabled","src","title","style","width","height","border","accept","_c","$RefreshReg$"],"sources":["/home/sv/LazyHacks/study-tracker-ui/src/pages/LearningAssist.js"],"sourcesContent":["// LearningAssist.js\n\nimport React, { useState } from 'react';\nimport { useNavigate } from 'react-router-dom';\nimport './LearningAssist.css';\nimport Header from '../components/Header';\n\nfunction LearningAssist() {\n  const [currentTab, setCurrentTab] = useState('Research Assistant');\n  const [arxivLink, setArxivLink] = useState('');\n  const [selectedFile, setSelectedFile] = useState(null);\n  const [pdfFile, setPdfFile] = useState(null);\n  const [videoFile, setVideoFile] = useState(null); // Added state for video file\n  const [notes, setNotes] = useState(null);\n  const navigate = useNavigate();\n\n  const handleLinkSubmission = () => {\n    setSelectedFile(arxivLink);\n    setArxivLink('');\n  };\n\n  const handleFileUpload = (event) => {\n    setPdfFile(event.target.files[0]);\n  };\n\n  const handleVideoUpload = (event) => {\n    setVideoFile(event.target.files[0]);\n  };\n\n  const navigateToSmartAssistant = () => {\n    if (pdfFile) {\n      navigate('/smart-assistant', { state: { uploadedFile: pdfFile.name } });\n    } else if (selectedFile) {\n      navigate('/smart-assistant', { state: { uploadedFile: selectedFile } });\n    }\n  };\n\n  const handleGenerateNotes = () => {\n    setNotes(\"These are the generated notes from the video...\"); // Placeholder text\n    setSummary(`MLP-Mixer: An All-MLP Architecture for Vision<br><br>\n      <strong>Authors:</strong> Ilya Tolstikhin, Neil Houlsby, Alexander Kolesnikov, Lucas Beyer, Xiaohua Zhai, et al.<br>\n      <strong>Source:</strong> Google Research, Brain Team<br><br>\n      ---\n      <h3>Background</h3>\n      Traditional computer vision models rely on either Convolutional Neural Networks (CNNs), which apply convolution operations to extract spatial features, or Vision Transformers (ViTs), which use self-attention to capture global dependencies. However, the authors challenge this paradigm by proposing that neither convolutions nor attention mechanisms are strictly necessary to achieve high performance in image classification.<br><br>\n      ---\n      <h3>Introduction to MLP-Mixer</h3>\n      The MLP-Mixer is a new approach that relies solely on Multi-Layer Perceptrons (MLPs) without any convolution or self-attention layers. The architecture consists of two primary layers: token-mixing MLPs and channel-mixing MLPs. Token-mixing MLPs combine information across different spatial locations, while channel-mixing MLPs mix features across channels at each spatial location. Together, these layers allow the model to learn both spatial and channel relationships in the data.<br><br>\n      ---\n      <h3>Architecture Design</h3>\n      The MLP-Mixer architecture processes images in non-overlapping patches, similarly to Vision Transformers. The patches are first projected linearly to create a matrix with dimensions corresponding to the number of patches and channels. Each MLP-Mixer layer contains:\n      <ul>\n        <li><strong>Token-mixing MLP:</strong> Processes spatial data across patches, facilitating the integration of spatial information.</li>\n        <li><strong>Channel-mixing MLP:</strong> Mixes channel data independently for each patch, capturing feature interactions across channels.</li>\n      </ul>\n      These layers are interleaved to enable a complete spatial and channel interaction across the image.<br><br>\n      ---\n      <h3>Experiments and Results</h3>\n      MLP-Mixer was pre-trained on large datasets (e.g., ImageNet, JFT-300M) and evaluated on various image classification benchmarks. When compared to CNNs and Transformers, MLP-Mixer achieved competitive results, especially on large datasets, with minimal complexity. It achieved up to 87.94% top-1 accuracy on ImageNet, demonstrating that even without convolutions or attention, it could perform on par with state-of-the-art models.<br><br>\n      ---\n      <h3>Conclusion</h3>\n      The MLP-Mixer presents a simple yet effective alternative for vision tasks, challenging the need for complex convolution or attention layers in achieving high accuracy. Its design opens up new possibilities for vision architectures by demonstrating that MLP-based structures can capture the necessary dependencies in image data. The authors hope this work inspires further research into MLP-based architectures across various domains.\n      `);\n  };\n\n  const renderContent = () => {\n    if (currentTab === 'Research Assistant') {\n      return (\n        <div className=\"link-input\">\n          <input\n            type=\"text\"\n            placeholder=\"Enter arXiv link\"\n            value={arxivLink}\n            onChange={(e) => setArxivLink(e.target.value)}\n          />\n          <button onClick={handleLinkSubmission}>View Paper</button>\n          <button\n            className=\"smart-assistant-button\"\n            onClick={navigateToSmartAssistant}\n            disabled={!selectedFile}\n          >\n            Smart Assistant\n          </button>\n          {selectedFile && (\n            <iframe\n              src={selectedFile}\n              title=\"Research Paper\"\n              style={{ width: '100%', height: '90vh', border: 'none' }}\n            />\n          )}\n        </div>\n      );\n    } else if (currentTab === 'Personal Tutor') {\n      return (\n        <div className=\"tutor-section\">\n          <input type=\"file\" onChange={handleFileUpload} />\n          <button\n            onClick={navigateToSmartAssistant}\n            disabled={!pdfFile}\n          >\n            Smart Assistant\n          </button>\n        </div>\n      );\n    } else if (currentTab === 'Video to Note Maker') {\n      return (\n        <div className=\"video-note-section\">\n          <p>Upload a video to generate notes.</p>\n          <input type=\"file\" accept=\"video/*\" onChange={handleVideoUpload} />\n          <button onClick={handleGenerateNotes} disabled={!videoFile}>Generate Notes</button>\n          {notes && (\n            <div className=\"notes-box\">\n              <p>{notes}</p>\n            </div>\n          )}\n        </div>\n      );\n    }\n  };\n\n  return (\n    <div className=\"learning-assist-page\">\n      <Header />\n      <div className=\"tab-buttons\">\n        <button onClick={() => setCurrentTab('Personal Tutor')}>Personal Tutor</button>\n        <button onClick={() => setCurrentTab('Research Assistant')}>Research Assistant</button>\n        <button onClick={() => setCurrentTab('Video to Note Maker')}>Video to Note Maker</button>\n      </div>\n      {renderContent()}\n    </div>\n  );\n}\n\nexport default LearningAssist;\n"],"mappings":";;AAAA;;AAEA,OAAOA,KAAK,IAAIC,QAAQ,QAAQ,OAAO;AACvC,SAASC,WAAW,QAAQ,kBAAkB;AAC9C,OAAO,sBAAsB;AAC7B,OAAOC,MAAM,MAAM,sBAAsB;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAE1C,SAASC,cAAcA,CAAA,EAAG;EAAAC,EAAA;EACxB,MAAM,CAACC,UAAU,EAAEC,aAAa,CAAC,GAAGR,QAAQ,CAAC,oBAAoB,CAAC;EAClE,MAAM,CAACS,SAAS,EAAEC,YAAY,CAAC,GAAGV,QAAQ,CAAC,EAAE,CAAC;EAC9C,MAAM,CAACW,YAAY,EAAEC,eAAe,CAAC,GAAGZ,QAAQ,CAAC,IAAI,CAAC;EACtD,MAAM,CAACa,OAAO,EAAEC,UAAU,CAAC,GAAGd,QAAQ,CAAC,IAAI,CAAC;EAC5C,MAAM,CAACe,SAAS,EAAEC,YAAY,CAAC,GAAGhB,QAAQ,CAAC,IAAI,CAAC,CAAC,CAAC;EAClD,MAAM,CAACiB,KAAK,EAAEC,QAAQ,CAAC,GAAGlB,QAAQ,CAAC,IAAI,CAAC;EACxC,MAAMmB,QAAQ,GAAGlB,WAAW,CAAC,CAAC;EAE9B,MAAMmB,oBAAoB,GAAGA,CAAA,KAAM;IACjCR,eAAe,CAACH,SAAS,CAAC;IAC1BC,YAAY,CAAC,EAAE,CAAC;EAClB,CAAC;EAED,MAAMW,gBAAgB,GAAIC,KAAK,IAAK;IAClCR,UAAU,CAACQ,KAAK,CAACC,MAAM,CAACC,KAAK,CAAC,CAAC,CAAC,CAAC;EACnC,CAAC;EAED,MAAMC,iBAAiB,GAAIH,KAAK,IAAK;IACnCN,YAAY,CAACM,KAAK,CAACC,MAAM,CAACC,KAAK,CAAC,CAAC,CAAC,CAAC;EACrC,CAAC;EAED,MAAME,wBAAwB,GAAGA,CAAA,KAAM;IACrC,IAAIb,OAAO,EAAE;MACXM,QAAQ,CAAC,kBAAkB,EAAE;QAAEQ,KAAK,EAAE;UAAEC,YAAY,EAAEf,OAAO,CAACgB;QAAK;MAAE,CAAC,CAAC;IACzE,CAAC,MAAM,IAAIlB,YAAY,EAAE;MACvBQ,QAAQ,CAAC,kBAAkB,EAAE;QAAEQ,KAAK,EAAE;UAAEC,YAAY,EAAEjB;QAAa;MAAE,CAAC,CAAC;IACzE;EACF,CAAC;EAED,MAAMmB,mBAAmB,GAAGA,CAAA,KAAM;IAChCZ,QAAQ,CAAC,iDAAiD,CAAC,CAAC,CAAC;IAC7Da,UAAU,CAAC;AACf;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,OAAO,CAAC;EACN,CAAC;EAED,MAAMC,aAAa,GAAGA,CAAA,KAAM;IAC1B,IAAIzB,UAAU,KAAK,oBAAoB,EAAE;MACvC,oBACEH,OAAA;QAAK6B,SAAS,EAAC,YAAY;QAAAC,QAAA,gBACzB9B,OAAA;UACE+B,IAAI,EAAC,MAAM;UACXC,WAAW,EAAC,kBAAkB;UAC9BC,KAAK,EAAE5B,SAAU;UACjB6B,QAAQ,EAAGC,CAAC,IAAK7B,YAAY,CAAC6B,CAAC,CAAChB,MAAM,CAACc,KAAK;QAAE;UAAAG,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAC/C,CAAC,eACFvC,OAAA;UAAQwC,OAAO,EAAExB,oBAAqB;UAAAc,QAAA,EAAC;QAAU;UAAAM,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAQ,CAAC,eAC1DvC,OAAA;UACE6B,SAAS,EAAC,wBAAwB;UAClCW,OAAO,EAAElB,wBAAyB;UAClCmB,QAAQ,EAAE,CAAClC,YAAa;UAAAuB,QAAA,EACzB;QAED;UAAAM,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAQ,CAAC,EACRhC,YAAY,iBACXP,OAAA;UACE0C,GAAG,EAAEnC,YAAa;UAClBoC,KAAK,EAAC,gBAAgB;UACtBC,KAAK,EAAE;YAAEC,KAAK,EAAE,MAAM;YAAEC,MAAM,EAAE,MAAM;YAAEC,MAAM,EAAE;UAAO;QAAE;UAAAX,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAC1D,CACF;MAAA;QAAAH,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OACE,CAAC;IAEV,CAAC,MAAM,IAAIpC,UAAU,KAAK,gBAAgB,EAAE;MAC1C,oBACEH,OAAA;QAAK6B,SAAS,EAAC,eAAe;QAAAC,QAAA,gBAC5B9B,OAAA;UAAO+B,IAAI,EAAC,MAAM;UAACG,QAAQ,EAAEjB;QAAiB;UAAAmB,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAE,CAAC,eACjDvC,OAAA;UACEwC,OAAO,EAAElB,wBAAyB;UAClCmB,QAAQ,EAAE,CAAChC,OAAQ;UAAAqB,QAAA,EACpB;QAED;UAAAM,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAQ,CAAC;MAAA;QAAAH,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OACN,CAAC;IAEV,CAAC,MAAM,IAAIpC,UAAU,KAAK,qBAAqB,EAAE;MAC/C,oBACEH,OAAA;QAAK6B,SAAS,EAAC,oBAAoB;QAAAC,QAAA,gBACjC9B,OAAA;UAAA8B,QAAA,EAAG;QAAiC;UAAAM,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAG,CAAC,eACxCvC,OAAA;UAAO+B,IAAI,EAAC,MAAM;UAACiB,MAAM,EAAC,SAAS;UAACd,QAAQ,EAAEb;QAAkB;UAAAe,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAE,CAAC,eACnEvC,OAAA;UAAQwC,OAAO,EAAEd,mBAAoB;UAACe,QAAQ,EAAE,CAAC9B,SAAU;UAAAmB,QAAA,EAAC;QAAc;UAAAM,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAQ,CAAC,EAClF1B,KAAK,iBACJb,OAAA;UAAK6B,SAAS,EAAC,WAAW;UAAAC,QAAA,eACxB9B,OAAA;YAAA8B,QAAA,EAAIjB;UAAK;YAAAuB,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAAI;QAAC;UAAAH,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OACX,CACN;MAAA;QAAAH,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OACE,CAAC;IAEV;EACF,CAAC;EAED,oBACEvC,OAAA;IAAK6B,SAAS,EAAC,sBAAsB;IAAAC,QAAA,gBACnC9B,OAAA,CAACF,MAAM;MAAAsC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAE,CAAC,eACVvC,OAAA;MAAK6B,SAAS,EAAC,aAAa;MAAAC,QAAA,gBAC1B9B,OAAA;QAAQwC,OAAO,EAAEA,CAAA,KAAMpC,aAAa,CAAC,gBAAgB,CAAE;QAAA0B,QAAA,EAAC;MAAc;QAAAM,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAQ,CAAC,eAC/EvC,OAAA;QAAQwC,OAAO,EAAEA,CAAA,KAAMpC,aAAa,CAAC,oBAAoB,CAAE;QAAA0B,QAAA,EAAC;MAAkB;QAAAM,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAQ,CAAC,eACvFvC,OAAA;QAAQwC,OAAO,EAAEA,CAAA,KAAMpC,aAAa,CAAC,qBAAqB,CAAE;QAAA0B,QAAA,EAAC;MAAmB;QAAAM,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAQ,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACtF,CAAC,EACLX,aAAa,CAAC,CAAC;EAAA;IAAAQ,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACb,CAAC;AAEV;AAACrC,EAAA,CA5HQD,cAAc;EAAA,QAOJJ,WAAW;AAAA;AAAAoD,EAAA,GAPrBhD,cAAc;AA8HvB,eAAeA,cAAc;AAAC,IAAAgD,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}